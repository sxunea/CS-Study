# 메모리 관리

## 가상 메모리

메모리 관리 기법 중 하나로, 메모리가 실제 메모리보다 많아 보이게 하는 기술.

어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하게 한다.
- 애플리케이션이 실행될때, 실행에 필요한 일부분만 메모리에 올라가며 애플리케이션의 나머지는 디스크에 남게 됨
- 빠르고 작은 기억장치(RAM)을 크고 느린 기억장치(디스크)와 병합해, 하나의 크고 빠른 기억장치(가상메모리)처럼 동작하게 함

![image](https://github.com/zeunxx/algorithm/assets/81572478/4f77a573-33bf-461f-9811-fb61d29e34f1)


<BR>

- 가상 주소(logical address): 가상적으로 주어진 주소
- 실제 주소(physical address): 실제 메모리 상에 있는 주소
- **MMU(Memory Management Unit) 메모리 관리 장치** : 가상주소를 물리주소로 변환하고, 메모리를 보호하는 기능을 수행함
    - MMY를 사용하면, CPU가 각 메모리에 접근하기 전에 메모리 주소 번역 작업이 수행 됨
    - BUT, 메모리를 일일히 가상 주소에서 물리 주소로 번역하면 작업 부하가 높아, MMU는 RAM을 여러부분(**페이지 page**)로 나누어 각 페이지를 하나의 독립된 항목으로 처리함
    - 페이지 및 주소 번역 정보를 기억하는 작업이 중요함
    - 가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어있는 **'페이지 테이블'**로 관리 됨

<br><Br>

## 요구 페이징 demand paging

CPU가 요청할때 프로세스의 데이터를 메모리에 올리는 것

= 처음부터 모든 데이터를 메모리에 적재하지 않음


<BR><br>

## TLB (Translation Lookaside Buffer, 페이지 정보 캐쉬)

가상 메모리 주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용하는 캐시 

- 최근에 일어난 가상메모리와 물리주소의 변환 테이블을 저장
- CPU가 가상 주소를 가지고 메모리에 접근하려 할때 우선 TLB에 접근해 가상 주소에 해당되는 물리 주소를 찾고, TLB에 매핑이 존재하지 않으면 MMU가 페이지 테이블에 해당되는 물리주소로 변환 후 메모리에 접근


<BR><BR>

## 페이지 폴트 page faults

어떤 페이지에 접근하려고 할때 해당 페이지가 실제 물리 메모리에 부재할때 뜨는 인터럽트.
- 어떤 프로그램이 자신의 주소공간(가상 메모리 공간)에는 존재하지만, 시스템의 RAM에는 현재 존재하지 않는 데이터/코드에 접근을 시도할 경우 발생

페이지 폴트가 발생하면 OS가 이를 해결한 뒤 다시 동일한 명령 수행
- 페이지 폴트 발생시 운영체제는 그 데이터를 메모리로 가져와서, 마치 페이지 폴트가 전혀 발생하지 않은 것처럼 작동하게 함
- 페이지 폴트가 자주 일어날 수록 운영체제의 성능이 저하되므로 페이지 폴트가 일어나지 않게 하는 것이 중요 
    ➡️ 페이지 폴트를 최소화하기 위해 **페이지 교체 정책** 사용


<bR>

- 페이지 교체 정책
    메모리가 꽉 차있을때 기존 페이지 중 하나늘 물리 메모리에서 저장 매체로 내리고, 새로운 패이지를 방금 비워진 해당 물리 공간에 올림. 이때 기존 페이지 중 어떤 것을 내리면 좋을지에 대한 알고리즘을 짠 것이 **페이지 교체 알고리즘**



### 스레싱

메모리의 페이지 폴트율이 높은 것을 의미하고, 컴퓨터의 심각한 성능 저하 유래

- 스레싱은 메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나서 발생
    - 스와핑: 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 메모리처럼 불러와 쓰는 것
- 페이지 폴트가 일어나면 CPU 이용률이 낮아짐 ➡️ CPU 이용률이 낮으면 가용성을 높이기 위해 더 많은 프로세스를 메모리에 올림 ➡️ 악순환


- 작업 세트 : 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어 미리 메모리에 로드하는 것. 미리 메모리에 로드하면 탐색에 드는 비용을 줄이고 스와핑 또한 줄음
- PFF(Page Fault Frequency) : 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 것. 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄임

<BR><BR>

## 메모리 할당

메모리에 프로그램을 할당할때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당한다.
이때 연속할당과 불연속할당으로 나뉜다. 

- 연속할당: 프로세스를 한꺼번에 메모리에 적재시킨다 (내부 단편화 발생)
- 불연속할당: 프로세스를 여러개로 쪼개어 메모리에 적재시킨다. (외부 단편화 발생)


<br>

## 연속 할당

프로세스가 하나의 연속된 메모리 공간에 할당되는 방식이다.

### 고정 분할 방식

메모리를 미리 나누어 관리하는 방식, 각 분할에 하나의 프로세스를 적재해 실행시킨다.


큰 프로세스가 메모리에 올라오면 여러 조각으로 나누어 배치한다.


- 장점: 메모리를 일정한 크기로 나누어 관리하므로 메모리 관리가 수월하다.
- 단점: 메모리가 미리 나뉘어 있으므로 융통성이 떨어져, 외부 단편화 및 내부 단편화 발생 가능하다.



<br>

**✅ 외부 단편화**

![image](https://github.com/sxunea/CS-Study/assets/81572478/27ac316b-bf2f-4be1-83aa-01596ab72bd4)


프로그램 크기보다 분할의 크기가 작은 경우 해당 분할이 비어있지만 프로그램을 적재하지 못하는 현상

<br>

**✅ 내부 단편화**

![image](https://github.com/sxunea/CS-Study/assets/81572478/bfc773e5-ec3f-46cc-bed2-79bdf88ccda1)

프로그램 크기보다 분할의 크기가 큰 경우, 해당 분할에 프로그램을 적재하고 남는 현상

<br><br>

### 가변 분할 방식

메모리가 적재되는 프로그램 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식.

프로그램 크기에 맞게 할당하므로 내부 단편화 발생 X

- 프로세스가 다 사용된 후 종료되어 메모리에서 내려가면 해당 공간은 메모리 가용공간(빈공간)이 된다(외부 단편화). 따라서 산발적으로 있는 가용공간 중 새로운 프로그램을 어디에 올릴지 결정하는 문제가 발생한다. = 동적 메모리 할당 문제

<BR>

- 동적 메모리 할당 문제를 해결하는 방법
  - 최초 적합: 할당 가능한 메모리 공간 중 가장 먼저 찾은 곳에 할당
    - 시간 측면에서 효율
  - 최적 적합: 할당 가능한 메모리 공간 중 크기가 가장 작은 곳에 할당
    - 공간 측면에서 효율, 모든 가용공간 탐색해야 하는 시간 오버헤드 발생
  - 최악 적합: 할당 가능한 메모리 공간 중 크기가 큰 곳에 할당
    - 시간 오버헤드 발생



<BR>

**✅ 메모리 컴팩션 Memory Compaction**

가변분할 방식에서 발생하는 외부조각 문제해결 위한 방법


프로세스가 종료된 자리에 생겨난 가용공간을 없애기 위해 적재된 프로세스들을 한쪽으로 몰아 가용공간을 하나의 큰 공간으로 만드는 것


BUT, 이 방법은 현재 수행중인 프로세스의 메모리상 위치를 상당 부분 이동시켜야 해서 비용이 매우 많이 든다.




<br><br>

## 불연속 할당

페이지를 연속적으로 할당하지 않는 방식

- Page : 프로세스를 고정된 크기의 작은 블록들로 나눴을 대, 그 블록들을 페이지라 함
- Frame : 페이지 크기와 같은 주 기억장치 메모리 블록
- Segment : 서로 다른 크기의 논리적 단위



- 페이징 기법: 고정분할방식을 이용
- 세그멘테이션 기법: 가변분할방식을 이용


<br>

### 페이징 Paging

고정 분할 방식을 이용한 가상 메모리 관리 기법으로, 물리 주소공간을 같은 크기(프레임)으로 나누어 사용한다.


![image](https://github.com/sxunea/CS-Study/assets/81572478/eef52dc5-b084-4f21-b360-9b2c3b881d6d)

- 가상 주소의 분할된 각 영역을 **페이지**라고 하며 번호를 매겨 관리한다.
- 물리 메모리의 각 영역은 **프레임**이라고 한다.
- 페이지와 프레임의 크기는 같으므로 페이지는 어떤 프레임에도 배치될 수 있다. (외부 단편화 발생 X, 내부 단편화는 발생 가능)
    - 마지막에 위치한 페이지는 프레임의 크기보다 작을 수 있다.
- 어떤 페이지가 어떤 프레임에 있는지 매핑 정보는 **페이지 테이블**에 담겨 있다.


<br>

### 세그멘테이션 Segmentation

페이징이 프로세스를 물리적으로 일정한 크기로 잘라서 메모리에 할당시키는 것이라면, 세그멘테이션은 프로세스를 논리적 내용을 기반으로 나누어 메모리에 배치하는 것.


프로세스는 코드, 데이터, 스택, 힙 등으로 이루어지는데, 이런 논리적인 영역/집합을 **세그먼트**라고 한다.
- 코드, 데이터 등을 기반으로 나눌 수 도 있고, 해당 코드 내에 특정 함수 세그먼트로 나누어 메모리에 할당 시킬 수 있다.
- 따라서 각 세그먼트는 동일하지 않은 크기를 갖는다.
    - 중간에 프로세스가 메모리를 해제하면 생기는 틈 발생 = 외부 단편화 발생
    - 프로세스가 필요한 메모리만큼 할당 = 내부 단편화 발생 x

<br>

### 페이지드 세그멘테이션 Paged Segmentation

세그멘테이션을 기본으로 하되, 이를 다시 동일 크기의 페이지로 나누어 메모리에 할당하는 기법


즉, 프로그램을 의미 단위의 segment로 나누고, 개별 segment의 크기를 page의 배수가 되게 한다. 


이를 통해 segmentation 기법에서 발생하는 외부 단편화 문제를 해결하고, 동시에 segment 단위로 프로세스간의 공유나 접근 권한 보호가 이루어지도록 해서 paging 기법의 단점을 해결한다.


<BR><BR>

## 페이지 교체 알고리즘


### FIFO 페이지 교체

가장 간단한 페이지 교체 알고리즘으로 FIFO(first-in first-out)의 흐름을 가진다. 즉, 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다는 것이다.

- 장점
    - 이해하기도 쉽고, 프로그램하기도 쉽다.
- 단점
    - 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있다(초기 변수 등)
    - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있다.
    - `Belady의 모순`: 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다.

### 최적 페이지 교체(Optimal Page Replacement)

`Belady의 모순`을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되었고, 모든 알고리즘보다 낮은 페이지 부재율을 보이며 `Belady의 모순`이 발생하지 않는다. 이 알고리즘의 핵심은 `앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`하는 것이다. 주로 비교 연구 목적을 위해 사용한다.

- 장점
    - 알고리즘 중 가장 낮은 페이지 부재율을 보장한다.
- 단점
    - 구현의 어려움이 있다. 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문이다.

### LRU 페이지 교체(LRU Page Replacement)

`LRU: Least-Recently-Used`

최적 알고리즘의 근사 알고리즘으로, 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다.

- 특징
    - 대체적으로 `FIFO 알고리즘`보다 우수하고, `OPT알고리즘`보다는 그렇지 못한 모습을 보인다.

### LFU 페이지 교체(LFU Page Replacement)

`LFU: Least Frequently Used`

참조 횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다.

- 특징
    - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다
    - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.